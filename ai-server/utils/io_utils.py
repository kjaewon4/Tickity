import os
import cv2
import numpy as np
from insightface.app import FaceAnalysis
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import io

# InsightFace ëª¨ë¸ ë¡œë“œ (ì „ì—­ ë³€ìˆ˜ë¡œ í•œ ë²ˆë§Œ ë¡œë“œ)
try:
    app = FaceAnalysis(name="buffalo_l", providers=['CPUExecutionProvider'])
    app.prepare(ctx_id=0)
    print("âœ… InsightFace ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
except Exception as e:
    print(f"âŒ InsightFace ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    app = None

def apply_clahe(image, clip_limit=2.0, tile_grid_size=(8, 8)):
    """CLAHEë¥¼ ì ìš©í•˜ì—¬ ì¡°ëª…ì„ ë³´ì •í•©ë‹ˆë‹¤."""
    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)
    l = clahe.apply(l)
    lab = cv2.merge([l, a, b])
    return cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)

def extract_embedding_from_video_optimized(video_bytes, frame_skip=2, det_score_threshold=0.2, yaw_threshold=60, num_clusters=5):
    """
    ë¹„ë””ì˜¤ì—ì„œ ì–¼êµ´ ì„ë² ë”©ì„ ì¶”ì¶œí•˜ëŠ” ê°œì„ ëœ í•¨ìˆ˜
    - KMeans í´ëŸ¬ìŠ¤í„°ë§ìœ¼ë¡œ ë‹¤ì–‘í•œ ê°ë„ì˜ ì–¼êµ´ ì„ ë³„
    - CLAHE ì „ì²˜ë¦¬ë¡œ ì¡°ëª… ë³´ì •
    - ì´ìƒì¹˜ ì œê±°ë¡œ í’ˆì§ˆ í–¥ìƒ
    """
    if app is None:
        print("âŒ InsightFace ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None

    # ë¹„ë””ì˜¤ ë°”ì´íŠ¸ë¥¼ ë©”ëª¨ë¦¬ ë²„í¼ë¡œ ë³€í™˜
    video_buffer = io.BytesIO(video_bytes)
    
    # OpenCVë¡œ ë¹„ë””ì˜¤ ì½ê¸° (ì„ì‹œ íŒŒì¼ ì‚¬ìš©)
    import tempfile
    with tempfile.NamedTemporaryFile(suffix='.webm', delete=False) as temp_file:
        temp_path = temp_file.name
        temp_file.write(video_bytes)
    
    cap = cv2.VideoCapture(temp_path)
    if not cap.isOpened():
        print("âŒ ë¹„ë””ì˜¤ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        try:
            os.unlink(temp_path)
        except:
            pass
        return None

    embeddings = []
    poses = []  # ì–¼êµ´ í¬ì¦ˆ ì •ë³´ ì €ì¥
    frame_count = 0

    print(f"ğŸ¬ ë¹„ë””ì˜¤ ë¶„ì„ ì‹œì‘ (frame_skip={frame_skip}, threshold={det_score_threshold})")

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        # í”„ë ˆì„ ìŠ¤í‚µ
        if frame_count % frame_skip != 0:
            frame_count += 1
            continue

        # CLAHE ì „ì²˜ë¦¬ ì ìš©
        frame = apply_clahe(frame)
        
        # ì–¼êµ´ ê°ì§€
        faces = app.get(frame)
        
        if faces:
            # ê°€ì¥ í° ì–¼êµ´ ì„ íƒ
            main_face = max(faces, key=lambda x: x.bbox[2] * x.bbox[3])
            
            # ì–¼êµ´ ê°ë„ ê³„ì‚° (yaw, pitch, roll)
            yaw = np.degrees(main_face.pose[1]) if hasattr(main_face, 'pose') else 0
            
            # ë””ë²„ê¹…: ëª¨ë“  ì–¼êµ´ ê°ì§€ ê²°ê³¼ ë¡œê·¸
            print(f"ğŸ” í”„ë ˆì„ {frame_count}: ì–¼êµ´ ê°ì§€ë¨ - det_score={main_face.det_score:.3f}, yaw={yaw:.1f}Â°")
            
            # í’ˆì§ˆ ê¸°ì¤€ í™•ì¸
            if main_face.det_score >= det_score_threshold and abs(yaw) <= yaw_threshold:
                embeddings.append(main_face.embedding)
                poses.append(abs(yaw))  # ì ˆëŒ“ê°’ìœ¼ë¡œ ì €ì¥
                print(f"âœ… í”„ë ˆì„ {frame_count}: ê¸°ì¤€ í†µê³¼!")
            else:
                print(f"âŒ í”„ë ˆì„ {frame_count}: ê¸°ì¤€ ë¯¸ë‹¬ (det_threshold={det_score_threshold}, yaw_threshold={yaw_threshold})")
        else:
            print(f"ğŸ‘» í”„ë ˆì„ {frame_count}: ì–¼êµ´ ê°ì§€ ì•ˆë¨")

        frame_count += 1

    cap.release()
    
    # ì„ì‹œ íŒŒì¼ ì •ë¦¬
    try:
        os.unlink(temp_path)
    except:
        pass
    
    if not embeddings:
        print("âŒ ì²« ë²ˆì§¸ ì‹œë„ ì‹¤íŒ¨. ë” ê´€ëŒ€í•œ ì„¤ì •ìœ¼ë¡œ ì¬ì‹œë„...")
        
        # ë‘ ë²ˆì§¸ ì‹œë„: ë” ê´€ëŒ€í•œ ì„¤ì •
        cap = cv2.VideoCapture(temp_path)
        frame_count = 0
        fallback_embeddings = []
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break

            # ëª¨ë“  í”„ë ˆì„ ë¶„ì„ (í”„ë ˆì„ ìŠ¤í‚µ ì—†ìŒ)
            frame = apply_clahe(frame, clip_limit=3.0, tile_grid_size=(4, 4))  # ë” ê°•í•œ CLAHE
            faces = app.get(frame)
            
            if faces:
                main_face = max(faces, key=lambda x: x.bbox[2] * x.bbox[3])
                # ë§¤ìš° ê´€ëŒ€í•œ ê¸°ì¤€ (ì„ê³„ê°’ 0.1, ê°ë„ ì œí•œ ì—†ìŒ)
                if main_face.det_score >= 0.1:
                    fallback_embeddings.append(main_face.embedding)
                    print(f"ğŸ”„ Fallback í”„ë ˆì„ {frame_count}: det_score={main_face.det_score:.3f}")

            frame_count += 1

        cap.release()
        
        if fallback_embeddings:
            embeddings = np.array(fallback_embeddings)
            print(f"âœ… Fallbackìœ¼ë¡œ {len(embeddings)}ê°œ ì„ë² ë”© ìˆ˜ì§‘")
        else:
            print("âŒ Fallbackì—ì„œë„ ì–¼êµ´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None

    embeddings = np.array(embeddings)
    print(f"ğŸ“Š ì´ {len(embeddings)}ê°œì˜ ì„ë² ë”© ìˆ˜ì§‘ë¨")

    # KMeans í´ëŸ¬ìŠ¤í„°ë§ìœ¼ë¡œ ë‹¤ì–‘í•œ ê°ë„ ëŒ€í‘œ ì„ ë³„
    if len(embeddings) > num_clusters:
        try:
            kmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init=10)
            cluster_labels = kmeans.fit_predict(embeddings)
            
            # ê° í´ëŸ¬ìŠ¤í„°ì—ì„œ ì¤‘ì‹¬ì— ê°€ì¥ ê°€ê¹Œìš´ ì„ë² ë”© ì„ íƒ
            selected_embeddings = []
            for i in range(num_clusters):
                cluster_embeddings = embeddings[cluster_labels == i]
                if len(cluster_embeddings) > 0:
                    # í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬ì— ê°€ì¥ ê°€ê¹Œìš´ ì„ë² ë”© ì„ íƒ
                    center = kmeans.cluster_centers_[i]
                    distances = np.linalg.norm(cluster_embeddings - center, axis=1)
                    best_idx = np.argmin(distances)
                    selected_embeddings.append(cluster_embeddings[best_idx])
            
            embeddings = np.array(selected_embeddings)
            print(f"ğŸ¯ KMeansë¡œ {len(embeddings)}ê°œ ëŒ€í‘œ ì„ë² ë”© ì„ ë³„")
            
        except Exception as e:
            print(f"âš ï¸ KMeans ì‹¤íŒ¨, ì›ë³¸ ì‚¬ìš©: {e}")

    # ì´ìƒì¹˜ ì œê±° (IQR ë°©ì‹)
    if len(embeddings) > 3:
        # ê° ì„ë² ë”©ì˜ í’ˆì§ˆì„ ë‹¤ë¥¸ ì„ë² ë”©ë“¤ê³¼ì˜ ìœ ì‚¬ë„ë¡œ ì¸¡ì •
        similarities = []
        for i, emb in enumerate(embeddings):
            other_embs = np.delete(embeddings, i, axis=0)
            sim_scores = np.dot(emb, other_embs.T)  # ì½”ì‚¬ì¸ ìœ ì‚¬ë„
            similarities.append(np.mean(sim_scores))
        
        similarities = np.array(similarities)
        q1, q3 = np.percentile(similarities, [25, 75])
        iqr = q3 - q1
        lower_bound = q1 - 1.5 * iqr
        upper_bound = q3 + 1.5 * iqr
        
        # ì´ìƒì¹˜ê°€ ì•„ë‹Œ ì„ë² ë”©ë§Œ ì„ íƒ
        valid_indices = np.where((similarities >= lower_bound) & (similarities <= upper_bound))[0]
        if len(valid_indices) > 0:
            embeddings = embeddings[valid_indices]
            print(f"ğŸ” ì´ìƒì¹˜ ì œê±° í›„ {len(embeddings)}ê°œ ì„ë² ë”© ìœ ì§€")

    # ìµœì¢… ì„ë² ë”© ê³„ì‚° (ê°€ì¤‘ í‰ê· )
    if len(embeddings) > 1:
        # í’ˆì§ˆ ê°€ì¤‘ì¹˜ ê³„ì‚° (ë‹¤ë¥¸ ì„ë² ë”©ë“¤ê³¼ì˜ ìœ ì‚¬ë„ ê¸°ë°˜)
        weights = []
        for emb in embeddings:
            others = embeddings[embeddings != emb].reshape(-1, embeddings.shape[1])
            if len(others) > 0:
                similarities = np.dot(emb, others.T)
                weight = np.mean(similarities)
            else:
                weight = 1.0
            weights.append(weight)
        
        weights = np.array(weights)
        weights = weights / np.sum(weights)  # ì •ê·œí™”
        
        # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ìµœì¢… ì„ë² ë”© ê³„ì‚°
        final_embedding = np.average(embeddings, axis=0, weights=weights)
        print(f"ğŸ¯ ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ìµœì¢… ì„ë² ë”© ìƒì„± (í’ˆì§ˆ ì ìˆ˜: {np.mean(weights):.3f})")
    else:
        final_embedding = embeddings[0]
        print("ğŸ“ ë‹¨ì¼ ì„ë² ë”© ì‚¬ìš©")

    return final_embedding


